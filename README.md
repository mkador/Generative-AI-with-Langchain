# Generative-AI-with-

# ðŸ“„ Resume Parser & LLM Experiments

This repository contains:
1. **LLM Experiments Notebook** â€” A Jupyter notebook exploring different Large Language Models (LLMs) and their capabilities.
2. **Resume Parser App** â€” A Streamlit-based application that uses Google's Gemini model to parse resumes into structured JSON format.

---

## ðŸš€ Features

- **Multiple LLM Integration**: Test and compare different models in the notebook.
- **Resume Parsing**: Upload resumes in PDF, DOCX, or TXT formats and extract:
  - Name
  - Email
  - Phone
  - LinkedIn
  - Skills
  - Education
  - Experience
  - Projects
  - Certifications
  - Languages
- **Automatic JSON Output**: Returns clean, structured JSON output for easy integration into other systems.

---

## ðŸ›  Technologies Used
- LangChain â€” LLM orchestration
- Google Gemini API â€” AI model for parsing
- Streamlit â€” Web app interface
- [PyPDFLoader, Docx2txtLoader, TextLoader] â€” Resume document loaders
- Python 3.9+

## ðŸ“‚ Project Structure
.
â”œâ”€â”€ 1_working_with_different_LLMs.ipynb   # LLM experiments notebook
â”œâ”€â”€ 2_Resume_Parser_app.py                # Streamlit resume parser app
â”œâ”€â”€ requirements.txt                       # Python dependencies
â””â”€â”€ README.md                              # Project documentation


## ðŸ”‘ Environment Variables
- Create a `.env` file in the root directory and add your Google API Key:
- GOOGLE_API_KEY=your_google_api_key_here


## ðŸ“¦ Installation

pip install langchain_openai langchain-google-genai python-dotenv streamlit
pip install -U langchain-community
pip install pypdf


```bash
# Clone the repository
git clone https://github.com/your-username/your-repo.git
cd your-repo

# Install dependencies
pip install -r requirements.txt
